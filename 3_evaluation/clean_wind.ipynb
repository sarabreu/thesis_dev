{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized partitional models\n",
    "clara_opt = pd.read_csv('../2_models/with_clean_data/wind/results/partitional_opt/csv_labels_raw/clara.csv')\n",
    "fuzzy_opt = pd.read_csv('../2_models/with_clean_data/wind/results/partitional_opt/csv_labels_raw/fuzzy_c_means.csv')\n",
    "kmeans_opt = pd.read_csv('../2_models/with_clean_data/wind/results/partitional_opt/csv_labels_raw/kmeans.csv')\n",
    "\n",
    "# partitional models\n",
    "clara = pd.read_csv('../2_models/with_clean_data/wind/results/partitional/csv_labels_raw/clara.csv')\n",
    "fuzzy = pd.read_csv('../2_models/with_clean_data/wind/results/partitional/csv_labels_raw/fuzzy_c_means.csv')\n",
    "kmeans = pd.read_csv('../2_models/with_clean_data/wind/results/partitional/csv_labels_raw/kmeans.csv')\n",
    "\n",
    "# model based\n",
    "bgmm = pd.read_csv('../2_models/with_clean_data/wind/results/model_based/csv_labels_cut_raw/bgmm.csv')\n",
    "# dpmm = pd.read_csv('../2_models/with_clean_data/wind/results/model_based/csv_labels_cut_raw/dpmm.csv')\n",
    "gaussian_mix = pd.read_csv('../2_models/with_clean_data/wind/results/model_based/csv_labels_cut_raw/gaussian_mix.csv')\n",
    "\n",
    "# optimized model based\n",
    "bgmm_opt = pd.read_csv('../2_models/with_clean_data/wind/results/model_based_opt/csv_labels_cut_raw/bgmm.csv')\n",
    "gaussian_mix_opt = pd.read_csv('../2_models/with_clean_data/wind/results/model_based_opt/csv_labels_cut_raw/gaussian_mix.csv')\n",
    "\n",
    "# optimized hierarchical models\n",
    "average_link_opt = pd.read_csv('../2_models/with_clean_data/wind/results/hierarchical_opt/csv_labels_cut_raw/average_link.csv')\n",
    "birch_opt = pd.read_csv('../2_models/with_clean_data/wind/results/hierarchical_opt/csv_labels_cut_raw/birch.csv')\n",
    "single_link_opt = pd.read_csv('../2_models/with_clean_data/wind/results/hierarchical_opt/csv_labels_cut_raw/single_link.csv')\n",
    "centroid_link_opt = pd.read_csv('../2_models/with_clean_data/wind/results/hierarchical_opt/csv_labels_cut_raw/centroid_link.csv')\n",
    "ward_link_opt = pd.read_csv('../2_models/with_clean_data/wind/results/hierarchical_opt/csv_labels_cut_raw/ward_link.csv')\n",
    "\n",
    "# hierarchical models\n",
    "average_link = pd.read_csv('../2_models/with_clean_data/wind/results/hierarchical/csv_labels_cut_raw/average_link.csv')\n",
    "birch = pd.read_csv('../2_models/with_clean_data/wind/results/hierarchical/csv_labels_cut_raw/birch.csv')\n",
    "single_link = pd.read_csv('../2_models/with_clean_data/wind/results/hierarchical/csv_labels_cut_raw/single_link.csv')\n",
    "centroid_link = pd.read_csv('../2_models/with_clean_data/wind/results/hierarchical/csv_labels_cut_raw/centroid_link.csv')\n",
    "ward_link = pd.read_csv('../2_models/with_clean_data/wind/results/hierarchical/csv_labels_cut_raw/ward_link.csv')\n",
    "\n",
    "# density based models\n",
    "dbscan = pd.read_csv('../2_models/with_clean_data/wind/results/density_based/csv_labels_cut_raw/DBSCAN.csv')\n",
    "optics = pd.read_csv('../2_models/with_clean_data/wind/results/density_based/csv_labels_cut_raw/OPTICS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, cdist\n",
    "\n",
    "def dunn_index(df):\n",
    "    points = df[['0', '1', '2']].values\n",
    "    labels = df['cluster_label'].values\n",
    "    unique_labels = np.unique(labels)\n",
    "    \n",
    "    max_intra_cluster_distances = []\n",
    "    min_inter_cluster_distance = float('inf')\n",
    "\n",
    "    for label in unique_labels:\n",
    "        cluster_points = points[labels == label]\n",
    "        if len(cluster_points) > 1:\n",
    "            intra_distances = pdist(cluster_points)\n",
    "            max_intra_cluster_distances.append(np.max(intra_distances))\n",
    "        else:\n",
    "            max_intra_cluster_distances.append(0)\n",
    "\n",
    "    for i, label_i in enumerate(unique_labels):\n",
    "        cluster_points_i = points[labels == label_i]\n",
    "        for j, label_j in enumerate(unique_labels):\n",
    "            if label_i < label_j:\n",
    "                cluster_points_j = points[labels == label_j]\n",
    "                inter_distances = cdist(cluster_points_i, cluster_points_j)\n",
    "                min_inter_cluster_distance = min(min_inter_cluster_distance, np.min(inter_distances))\n",
    "\n",
    "    if len(max_intra_cluster_distances) == 0 or min_inter_cluster_distance == float('inf'):\n",
    "        return 0\n",
    "\n",
    "    return min_inter_cluster_distance / max(max_intra_cluster_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def xie_beni_index(df):\n",
    "#     # Compute the total scatter\n",
    "#     total_scatter = np.sum(pdist(df[['0', '1', '2']]) ** 2) / (2 * len(df))\n",
    "    \n",
    "#     # Compute the intra-cluster scatter\n",
    "#     cluster_labels = df['cluster_label'].unique()\n",
    "#     intra_cluster_scatter = 0\n",
    "#     for label in cluster_labels:\n",
    "#         cluster_points = df[df['cluster_label'] == label][['0', '1', '2']]\n",
    "#         cluster_center = np.mean(cluster_points, axis=0)\n",
    "#         intra_cluster_scatter += np.sum(np.linalg.norm(cluster_points - cluster_center, axis=1) ** 2)\n",
    "#     intra_cluster_scatter /= len(df)\n",
    "#     return intra_cluster_scatter / total_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute evaluation metrics\n",
    "def compute_metrics(df):\n",
    "    metrics = {}\n",
    "    \n",
    "    if df['cluster_label'].nunique() > 1:\n",
    "        metrics['Silhouette Score'] = silhouette_score(df[['0', '1', '2']], df['cluster_label'])\n",
    "        metrics['Davies-Bouldin Index'] = davies_bouldin_score(df[['0', '1', '2']], df['cluster_label'])\n",
    "        metrics['Calinski-Harabasz Index'] = calinski_harabasz_score(df[['0', '1', '2']], df['cluster_label'])\n",
    "        metrics['Dunn Index'] = dunn_index(df)\n",
    "        # metrics['Xie-Beni Index'] = xie_beni_index(df)\n",
    "    else:\n",
    "        metrics['Silhouette Score'] = 0\n",
    "        metrics['Davies-Bouldin Index'] = 0\n",
    "        metrics['Calinski-Harabasz Index'] = 0\n",
    "        metrics['Dunn Index'] = 0\n",
    "        # metrics['Xie-Beni Index'] = 0\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'clara_opt': clara_opt, 'fuzzy_opt': fuzzy_opt, 'kmeans_opt': kmeans_opt,\n",
    "    'clara': clara, 'fuzzy': fuzzy, 'kmeans': kmeans,\n",
    "    'bgmm': bgmm, 'gaussian_mix': gaussian_mix,\n",
    "    'average_link_opt': average_link_opt, 'birch_opt': birch_opt,\n",
    "    'single_link_opt': single_link_opt, 'centroid_link_opt': centroid_link_opt,\n",
    "    'ward_link_opt': ward_link_opt,\n",
    "    'average_link': average_link, 'birch': birch, 'single_link': single_link,\n",
    "    'centroid_link': centroid_link, 'ward_link': ward_link,\n",
    "    'dbscan': dbscan, 'optics': optics,\n",
    "    'bgmm_optimized': bgmm_opt, 'gaussian_mix_opt' : gaussian_mix_opt\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe 'fuzzy_opt' does not have a column named 'cluster_label'.\n",
      "Index(['0', '1', '2', 'cluster', 'asset_id'], dtype='object')\n",
      "The dataframe 'kmeans_opt' does not have a column named 'cluster_label'.\n",
      "Index(['0', '1', '2', 'cluster', 'asset_id'], dtype='object')\n",
      "The dataframe 'clara' does not have a column named 'cluster_label'.\n",
      "Index(['0', '1', '2', 'cluster', 'asset_id'], dtype='object')\n",
      "The dataframe 'fuzzy' does not have a column named 'cluster_label'.\n",
      "Index(['0', '1', '2', 'cluster', 'asset_id'], dtype='object')\n",
      "The dataframe 'kmeans' does not have a column named 'cluster_label'.\n",
      "Index(['0', '1', '2', 'cluster', 'asset_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each dataframe and print the name of the ones without a 'cluster_label' column\n",
    "for model_name, df in dataframes.items():\n",
    "    if 'cluster_label' not in df.columns:\n",
    "        print(f\"The dataframe '{model_name}' does not have a column named 'cluster_label'.\")\n",
    "        print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each dataframe and rename the 'cluster' column to 'cluster_label'\n",
    "for model_name, df in dataframes.items():\n",
    "    if 'cluster' in df.columns:\n",
    "        df.rename(columns={'cluster': 'cluster_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating clara_opt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fuzzy_opt\n",
      "Evaluating kmeans_opt\n",
      "Evaluating clara\n",
      "Evaluating fuzzy\n",
      "Evaluating kmeans\n",
      "Evaluating bgmm\n",
      "Evaluating gaussian_mix\n",
      "Evaluating average_link_opt\n",
      "Evaluating birch_opt\n",
      "Evaluating single_link_opt\n",
      "Evaluating centroid_link_opt\n",
      "Evaluating ward_link_opt\n",
      "Evaluating average_link\n",
      "Evaluating birch\n",
      "Evaluating single_link\n",
      "Evaluating centroid_link\n",
      "Evaluating ward_link\n",
      "Evaluating dbscan\n",
      "Evaluating optics\n",
      "Evaluating bgmm_optimized\n",
      "Evaluating gaussian_mix_opt\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Compute and store the evaluation metrics for each dataframe\n",
    "for model_name, df in dataframes.items():\n",
    "    print(f'Evaluating {model_name}')\n",
    "    metrics = compute_metrics(df)\n",
    "    results.append({'Model': model_name, **metrics})\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "# list\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('results/clean_wind.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('results/clean_wind.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Closeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kmeans_opt</td>\n",
       "      <td>0.999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clara</td>\n",
       "      <td>0.930068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fuzzy</td>\n",
       "      <td>0.930068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.930068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>birch</td>\n",
       "      <td>0.773955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clara_opt</td>\n",
       "      <td>0.745784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ward_link</td>\n",
       "      <td>0.717852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ward_link_opt</td>\n",
       "      <td>0.651459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuzzy_opt</td>\n",
       "      <td>0.627315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gaussian_mix</td>\n",
       "      <td>0.597507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>birch_opt</td>\n",
       "      <td>0.581833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bgmm</td>\n",
       "      <td>0.545727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gaussian_mix_opt</td>\n",
       "      <td>0.339442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bgmm_optimized</td>\n",
       "      <td>0.297124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>optics</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dbscan</td>\n",
       "      <td>0.000930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>centroid_link</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>centroid_link_opt</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>average_link</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>single_link_opt</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>single_link</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>average_link_opt</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Closeness\n",
       "2          kmeans_opt   0.999963\n",
       "3               clara   0.930068\n",
       "4               fuzzy   0.930068\n",
       "5              kmeans   0.930068\n",
       "14              birch   0.773955\n",
       "0           clara_opt   0.745784\n",
       "17          ward_link   0.717852\n",
       "12      ward_link_opt   0.651459\n",
       "1           fuzzy_opt   0.627315\n",
       "7        gaussian_mix   0.597507\n",
       "9           birch_opt   0.581833\n",
       "6                bgmm   0.545727\n",
       "21   gaussian_mix_opt   0.339442\n",
       "20     bgmm_optimized   0.297124\n",
       "19             optics   0.001358\n",
       "18             dbscan   0.000930\n",
       "16      centroid_link   0.000400\n",
       "11  centroid_link_opt   0.000400\n",
       "13       average_link   0.000130\n",
       "10    single_link_opt   0.000130\n",
       "15        single_link   0.000130\n",
       "8    average_link_opt   0.000130"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert columns to numeric data types\n",
    "normalized_df = results_df.copy()\n",
    "for col in normalized_df.columns[1:]:\n",
    "    normalized_df[col] = pd.to_numeric(normalized_df[col], errors='coerce')\n",
    "\n",
    "# Drop rows with missing or non-numeric values\n",
    "normalized_df = normalized_df.dropna()\n",
    "\n",
    "# Define ideal and anti-ideal solutions for each metric\n",
    "ideal_solution = normalized_df.copy()\n",
    "anti_ideal_solution = normalized_df.copy()\n",
    "\n",
    "# Define metrics where higher values are better\n",
    "higher_is_better = ['Silhouette Score', 'Dunn Index', 'Calinski-Harabasz Index']\n",
    "\n",
    "# Define metrics where lower values are better\n",
    "lower_is_better = ['Davies-Bouldin Index']\n",
    "\n",
    "# Set ideal and anti-ideal solutions for metrics where higher values are better\n",
    "for metric in higher_is_better:\n",
    "    ideal_solution[metric] = normalized_df[metric].max()\n",
    "    anti_ideal_solution[metric] = normalized_df[metric].min()\n",
    "\n",
    "# Set ideal and anti-ideal solutions for metrics where lower values are better\n",
    "for metric in lower_is_better:\n",
    "    ideal_solution[metric] = normalized_df[metric].min()\n",
    "    anti_ideal_solution[metric] = normalized_df[metric].max()\n",
    "\n",
    "# Calculate the distance from each alternative to the ideal and anti-ideal solutions\n",
    "dist_to_ideal = ((normalized_df.iloc[:,1:] - ideal_solution) ** 2).sum(axis=1) ** 0.5\n",
    "dist_to_anti_ideal = ((normalized_df.iloc[:,1:] - anti_ideal_solution) ** 2).sum(axis=1) ** 0.5\n",
    "\n",
    "# Calculate the relative closeness to the ideal solution\n",
    "normalized_df['Closeness'] = dist_to_anti_ideal / (dist_to_ideal + dist_to_anti_ideal)\n",
    "\n",
    "# Sort the models based on their relative closeness to the ideal solution\n",
    "ranked_models = normalized_df.sort_values(by='Closeness', ascending=False)\n",
    "\n",
    "# Print the ranked models\n",
    "ranked_models[['Model', 'Closeness']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 best models: kmeans_opt, clara, fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Silhouette Score</th>\n",
       "      <th>Davies-Bouldin Index</th>\n",
       "      <th>Calinski-Harabasz Index</th>\n",
       "      <th>Dunn Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kmeans_opt</td>\n",
       "      <td>0.327644</td>\n",
       "      <td>0.961178</td>\n",
       "      <td>24421.654602</td>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clara</td>\n",
       "      <td>0.307441</td>\n",
       "      <td>1.033407</td>\n",
       "      <td>22714.942875</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fuzzy</td>\n",
       "      <td>0.307441</td>\n",
       "      <td>1.033407</td>\n",
       "      <td>22714.942875</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  Silhouette Score  Davies-Bouldin Index  \\\n",
       "2  kmeans_opt          0.327644              0.961178   \n",
       "3       clara          0.307441              1.033407   \n",
       "4       fuzzy          0.307441              1.033407   \n",
       "\n",
       "   Calinski-Harabasz Index  Dunn Index  \n",
       "2             24421.654602    0.000834  \n",
       "3             22714.942875    0.001102  \n",
       "4             22714.942875    0.001102  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.iloc[[2,3,4]] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
